{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OpenAI Gym CartPole Environment\n",
    "\n",
    "![](CartPole.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenAI Gym website contains information about widely used environments for testing reinforcement learning algorithms. It is at [https://gym.openai.com/](https://gym.openai.com/). This notebook demonstrates the steps to go through the Getting Started information at [Getting Started with Gym](https://gym.openai.com/docs/).\n",
    "\n",
    "OpenAI Gym also has a GitHub site at [https://github.com/openai/gym/](https://github.com/openai/gym/). More information about the CartPole problem can be found at [CartPole Wiki](https://github.com/openai/gym/wiki/CartPole-v0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OpenAI Gym Installation ##\n",
    "OpenAI gym is not installed as part of the Anaconda Python or standard Python distributions.  You need to install it from your command prompt or terminal. \n",
    "\n",
    "For Anaconda Python remember, to activate your Python (base) environment.\n",
    "```text\n",
    "conda activate base\n",
    "```\n",
    "Then use *conda* to install gym.\n",
    "```text\n",
    "conda install -c conda-forge gym\n",
    "```\n",
    "\n",
    "Use *pip* for the standard Python install.\n",
    "\n",
    "```text\n",
    "pip install gym\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started with Gym ###\n",
    "Next, we will go through the [Getting Started with Gym](https://gym.openai.com/docs/) examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started Example 1 ###\n",
    "\n",
    "You may be excited to try the first example and see the cart and pole move around on your screen. I know that I was! However, there are problems rendering graphics from within the Jupyter environment. To circumvent these problems you can place the code in a .py file and then run Python on it from the terminal or command prompt window.\n",
    "\n",
    "You can also run the code from within the Jupyter environment using the Launcher. Select Textfile from the Launcher and paste the code below into the window. Then rename the file to 'cartpole1.py' and save it. Open a terminal from the Launcher. There run the command\n",
    "```bash\n",
    "python cartpole1.py\n",
    "```\n",
    "\n",
    "Below is the contents pf the cartpol1.py file\n",
    "```python\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()\n",
    "```\n",
    "\n",
    "In the figure below you can see the cartpole1.py that has been pasted into a Textfile.\n",
    "\n",
    "![](PythonFile1.png)\n",
    "\n",
    "In this figre you see the terminal window with the execution of python on the file cartpole1.py. (Ignore the wwarning for now.)\n",
    "\n",
    "![](Terminal1.png)\n",
    "\n",
    "Here you see one frame of the rendered image.\n",
    "\n",
    "![](RenderedCartPole.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started Example 2 ####\n",
    "\n",
    "Below is the second example. I used the same process to create a .py ilfe  \n",
    "```python\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()\n",
    "```\n",
    "\n",
    "Upon execution, this renders the cartpole problem until the 'done' flag is True and then starts over again. This is done 100 times. In addition to rendering a movie of the cart pole pole, it prints out the state information at each step and then the total number of steps executed until the done flag is set to true as shown below.\n",
    "\n",
    "![](Terminal2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example ####\n",
    "1. Import the gym environment\n",
    "2. Instantiate the Cart Pole environment\n",
    "3. Print information on the observation space\n",
    "4. Print information about the action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
      "Action Space: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "print('Observation Space:', env.observation_space)\n",
    "print('Action Space:', env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example ####\n",
    "1. Print the largest values in the observation space\n",
    "2. Print the smallest values in the observation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "low:  [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print('high:',env.observation_space.high)\n",
    "print('low: ', env.observation_space.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example ####\n",
    "Reset the observation space to place the cart and pole into an initial state. The four observation values are set to random small numbers to start the problem. These values will be different each time you start the problem. The four values are\n",
    "\n",
    "1. Position of the cart\n",
    "2. Velocity of the cart\n",
    "3. Angular position of the end of the pole\n",
    "4. Angular velocity of the end of the pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01128073,  0.02070885, -0.02623478,  0.02326702])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
